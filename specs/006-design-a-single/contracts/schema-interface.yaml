# SQLite Database Schema Contract
# Feature: Optimized Database Schema for Code Index Storage
# Version: 1.0.0
# Date: 2025-10-13

version: "1.0.0"
description: >
  API contract for the SQLite database schema used by code-index.
  Defines tables, indexes, query interfaces, migration contracts, and logging requirements.
  All performance targets are based on medium-sized repositories (10k-100k files, 100k+ symbols).

# =============================================================================
# SCHEMA CONTRACT - Database Level
# =============================================================================

schema:
  database_file: ".codeindex/index.db"
  sqlite_version: ">=3.35.0"  # Minimum version for FTS5 and modern features
  encoding: "UTF-8"

  # Core PRAGMA settings - MUST be applied on every connection
  pragma_settings:
    journal_mode:
      value: "WAL"
      description: "Write-Ahead Logging for concurrent readers during writes"
      persistent: true  # Stored in database file

    synchronous:
      value: "NORMAL"
      description: "Balance safety and performance (safe with WAL mode)"
      options: ["OFF", "NORMAL", "FULL", "EXTRA"]
      default: "NORMAL"

    cache_size:
      value: -64000
      description: "64MB page cache (negative value = kibibytes)"
      unit: "kibibytes"

    temp_store:
      value: "MEMORY"
      description: "Store temporary tables and indexes in memory"
      options: ["DEFAULT", "FILE", "MEMORY"]

    mmap_size:
      value: 30000000000
      description: "30GB memory-mapped I/O (virtual addressing, not physical RAM)"
      unit: "bytes"

    wal_autocheckpoint:
      value: 1000
      description: "Checkpoint WAL every 1000 pages"
      unit: "pages"

    foreign_keys:
      value: "ON"
      description: "Enforce foreign key constraints"
      required: true

  # Table definitions
  tables:
    # -------------------------------------------------------------------------
    # FILES TABLE
    # -------------------------------------------------------------------------
    files:
      purpose: "Store metadata for all indexed source code files"
      columns:
        - name: "id"
          type: "TEXT"
          constraints: ["PRIMARY KEY", "NOT NULL"]
          description: "Unique identifier (UUID v4 or content-derived hash)"

        - name: "file_path"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Project-relative file path (e.g., 'src/index.ts')"

        - name: "content_hash"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "SHA-256 hash of file content for change detection"

        - name: "language"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Programming language (e.g., 'typescript', 'python')"

        - name: "size"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          description: "File size in bytes"

        - name: "modified_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          description: "Last modification timestamp (Unix epoch seconds)"

        - name: "created_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Record creation timestamp (Unix epoch seconds)"

        - name: "deleted_at"
          type: "INTEGER"
          constraints: []
          default: "NULL"
          description: "Soft delete timestamp (NULL = active, unix timestamp = deleted)"

      indexes:
        - name: "idx_files_path"
          type: "UNIQUE"
          columns: ["file_path"]
          where: "deleted_at IS NULL"
          purpose: "Ensure unique active file paths and fast path lookups"

        - name: "idx_files_hash"
          type: "INDEX"
          columns: ["content_hash"]
          purpose: "Detect duplicate content and changed files"

      foreign_keys: []

      performance_targets:
        - operation: "lookup_by_path"
          target: "<10ms"
          query: "SELECT * FROM files WHERE file_path = ? AND deleted_at IS NULL"

        - operation: "changed_files"
          target: "<50ms"
          query: "SELECT * FROM files WHERE content_hash != ?"

    # -------------------------------------------------------------------------
    # SYMBOLS TABLE
    # -------------------------------------------------------------------------
    symbols:
      purpose: "Store code symbols (functions, classes, variables) with location and metadata"
      columns:
        - name: "id"
          type: "TEXT"
          constraints: ["PRIMARY KEY", "NOT NULL"]
          description: "Unique identifier (UUID v4). New ID on rename/refactor."

        - name: "file_id"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Foreign key to files table"

        - name: "symbol_name"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Symbol identifier (e.g., 'myFunction', 'MyClass')"

        - name: "symbol_type"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Symbol kind (function, class, method, variable, interface, etc.)"

        - name: "signature"
          type: "TEXT"
          constraints: []
          description: "Function/method signature or type definition"

        - name: "documentation"
          type: "TEXT"
          constraints: []
          description: "Docstring, JSDoc, or inline documentation"

        - name: "line_start"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          description: "Starting line number (1-indexed)"

        - name: "line_end"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          description: "Ending line number (inclusive)"

        - name: "created_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Record creation timestamp"

        - name: "deleted_at"
          type: "INTEGER"
          constraints: []
          default: "NULL"
          description: "Soft delete timestamp (30-day retention, then purged)"

      indexes:
        - name: "idx_symbols_name"
          type: "INDEX"
          columns: ["symbol_name"]
          where: "deleted_at IS NULL"
          purpose: "Fast symbol lookup by name (partial index excludes deleted)"

        - name: "idx_symbols_file_type"
          type: "INDEX"
          columns: ["file_id", "symbol_type"]
          where: "deleted_at IS NULL"
          purpose: "Compound index for file symbols (leftmost prefix matching)"

        - name: "idx_symbols_deleted"
          type: "INDEX"
          columns: ["deleted_at"]
          where: "deleted_at IS NOT NULL"
          purpose: "Fast cleanup of expired deleted symbols"

      foreign_keys:
        - column: "file_id"
          references: "files(id)"
          on_delete: "CASCADE"
          description: "Cascade delete symbols when file is removed"

      performance_targets:
        - operation: "lookup_by_name"
          target: "<50ms"
          query: "SELECT * FROM symbols WHERE symbol_name = ? AND deleted_at IS NULL"

        - operation: "lookup_by_file"
          target: "<50ms"
          query: "SELECT * FROM symbols WHERE file_id = ? AND deleted_at IS NULL"

        - operation: "cleanup_deleted"
          target: "<1s per 10k records"
          query: "DELETE FROM symbols WHERE deleted_at < ?"

    # -------------------------------------------------------------------------
    # XREFS TABLE (Cross-References)
    # -------------------------------------------------------------------------
    xrefs:
      purpose: "Store cross-references between symbols (usage relationships)"
      columns:
        - name: "id"
          type: "INTEGER"
          constraints: ["PRIMARY KEY", "AUTOINCREMENT"]
          description: "Auto-incrementing unique identifier"

        - name: "source_symbol_id"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Symbol that references another (the referrer)"

        - name: "target_symbol_id"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Symbol being referenced (the referee)"

        - name: "reference_type"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Type of reference (call, import, extends, implements, usage)"

        - name: "line_number"
          type: "INTEGER"
          constraints: []
          description: "Line number where reference occurs (optional)"

        - name: "created_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Record creation timestamp"

      indexes:
        - name: "idx_xrefs_source"
          type: "INDEX"
          columns: ["source_symbol_id"]
          purpose: "Find all references from a symbol (outbound)"

        - name: "idx_xrefs_target"
          type: "INDEX"
          columns: ["target_symbol_id"]
          purpose: "Find all references to a symbol (inbound, 'find usages')"

        - name: "idx_xrefs_type"
          type: "INDEX"
          columns: ["reference_type"]
          purpose: "Query by reference type (e.g., all imports)"

      foreign_keys:
        - column: "source_symbol_id"
          references: "symbols(id)"
          on_delete: "CASCADE"
          description: "Delete xrefs when source symbol is removed"

        - column: "target_symbol_id"
          references: "symbols(id)"
          on_delete: "CASCADE"
          description: "Delete xrefs when target symbol is removed"

      performance_targets:
        - operation: "find_usages"
          target: "<100ms"
          query: "SELECT * FROM xrefs WHERE target_symbol_id = ?"

        - operation: "traverse_references"
          target: "<100ms"
          query: "SELECT * FROM xrefs WHERE source_symbol_id = ?"

    # -------------------------------------------------------------------------
    # CALLS TABLE
    # -------------------------------------------------------------------------
    calls:
      purpose: "Store function/method call relationships for call graph analysis"
      columns:
        - name: "id"
          type: "INTEGER"
          constraints: ["PRIMARY KEY", "AUTOINCREMENT"]
          description: "Auto-incrementing unique identifier"

        - name: "caller_symbol_id"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Symbol that makes the call"

        - name: "callee_symbol_id"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Symbol being called"

        - name: "call_type"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Type of call (direct, indirect, dynamic)"

        - name: "line_number"
          type: "INTEGER"
          constraints: []
          description: "Line number where call occurs"

        - name: "created_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Record creation timestamp"

      indexes:
        - name: "idx_calls_caller"
          type: "INDEX"
          columns: ["caller_symbol_id", "callee_symbol_id"]
          purpose: "Compound index for call graph traversal (leftmost prefix)"

        - name: "idx_calls_callee"
          type: "INDEX"
          columns: ["callee_symbol_id"]
          purpose: "Find all callers of a function (reverse call graph)"

      foreign_keys:
        - column: "caller_symbol_id"
          references: "symbols(id)"
          on_delete: "CASCADE"

        - column: "callee_symbol_id"
          references: "symbols(id)"
          on_delete: "CASCADE"

      performance_targets:
        - operation: "find_callers"
          target: "<100ms"
          query: "SELECT * FROM calls WHERE callee_symbol_id = ?"

        - operation: "find_callees"
          target: "<100ms"
          query: "SELECT * FROM calls WHERE caller_symbol_id = ?"

    # -------------------------------------------------------------------------
    # CHUNKS TABLE
    # -------------------------------------------------------------------------
    chunks:
      purpose: "Store semantic code chunks at function/method granularity for AI processing"
      columns:
        - name: "id"
          type: "TEXT"
          constraints: ["PRIMARY KEY", "NOT NULL"]
          description: "Stable identifier (content-derived hash for deduplication)"

        - name: "file_id"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Foreign key to files table"

        - name: "symbol_id"
          type: "TEXT"
          constraints: []
          description: "Associated symbol (optional, for function/method chunks)"

        - name: "content"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Chunk text content (code + comments)"

        - name: "context"
          type: "TEXT"
          constraints: []
          description: "Surrounding context (imports, class definition, etc.)"

        - name: "line_start"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          description: "Starting line number"

        - name: "line_end"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          description: "Ending line number"

        - name: "created_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Record creation timestamp"

        - name: "deleted_at"
          type: "INTEGER"
          constraints: []
          default: "NULL"
          description: "Soft delete timestamp"

      indexes:
        - name: "idx_chunks_file"
          type: "INDEX"
          columns: ["file_id"]
          where: "deleted_at IS NULL"
          purpose: "Find all chunks for a file"

        - name: "idx_chunks_symbol"
          type: "INDEX"
          columns: ["symbol_id"]
          where: "deleted_at IS NULL"
          purpose: "Find chunk for a specific symbol"

      foreign_keys:
        - column: "file_id"
          references: "files(id)"
          on_delete: "CASCADE"

        - column: "symbol_id"
          references: "symbols(id)"
          on_delete: "SET NULL"
          description: "Allow orphaned chunks when symbol deleted"

      performance_targets:
        - operation: "lookup_by_file"
          target: "<50ms"
          query: "SELECT * FROM chunks WHERE file_id = ? AND deleted_at IS NULL"

    # -------------------------------------------------------------------------
    # EMBEDDINGS TABLE
    # -------------------------------------------------------------------------
    embeddings:
      purpose: "Store 384-dimensional vector embeddings for semantic similarity search"
      columns:
        - name: "chunk_id"
          type: "TEXT"
          constraints: ["PRIMARY KEY", "NOT NULL"]
          description: "Foreign key to chunks table (1:1 relationship)"

        - name: "embedding"
          type: "BLOB"
          constraints: ["NOT NULL"]
          description: "384-dim float32 vector (1,536 bytes, IEEE 754 encoding)"

        - name: "created_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Record creation timestamp"

      indexes: []  # No indexes needed; brute-force scan expected for similarity

      foreign_keys:
        - column: "chunk_id"
          references: "chunks(id)"
          on_delete: "CASCADE"

      performance_targets:
        - operation: "similarity_search"
          target: "<200ms for 100k vectors"
          description: "Brute-force cosine similarity in application code"
          note: "Application-level operation, not a SQL query"

      encoding_details:
        format: "IEEE 754 32-bit float (little-endian)"
        dimensions: 384
        bytes_per_vector: 1536
        storage_per_100k_vectors: "~150MB"

    # -------------------------------------------------------------------------
    # SEARCH TABLE (FTS5 Virtual Table)
    # -------------------------------------------------------------------------
    search:
      purpose: "Full-text search across code content and documentation"
      type: "VIRTUAL TABLE"
      using: "fts5"
      columns:
        - name: "content"
          description: "Code content to be indexed"
          indexed: true

        - name: "documentation"
          description: "Comments and docstrings to be indexed"
          indexed: true

        - name: "file_path"
          description: "File path (not indexed, returned with results)"
          indexed: false
          type: "UNINDEXED"

        - name: "symbol_id"
          description: "Associated symbol ID (not indexed)"
          indexed: false
          type: "UNINDEXED"

      fts5_config:
        tokenizer: "unicode61"
        tokenizer_options:
          remove_diacritics: 1
          tokenchars: '"_."'
          description: "Treat underscores and dots as part of tokens (e.g., my_function, module.method)"

        ranking: "BM25"
        ranking_description: >
          Built-in BM25 ranking with configurable column weights.
          Lower scores are more relevant (negative scale, less negative = better match).

      performance_targets:
        - operation: "keyword_search"
          target: "<100ms for 1GB codebase"
          query: "SELECT *, bm25(search) as rank FROM search WHERE search MATCH ? ORDER BY rank LIMIT 100"

        - operation: "phrase_search"
          target: "<100ms"
          query: "SELECT * FROM search WHERE search MATCH '\"exact phrase\"' ORDER BY rank LIMIT 100"

      usage_notes:
        - "FTS5 automatically creates its own indexes"
        - "Use MATCH operator for full-text queries, not LIKE"
        - "Prefix queries: 'get*' matches 'getUser', 'getData', etc."
        - "Phrase queries: '\"function call\"' for exact phrase"
        - "BM25 column weights: bm25(search, 2.0, 1.0) weights content 2x higher than docs"

    # -------------------------------------------------------------------------
    # META TABLE
    # -------------------------------------------------------------------------
    meta:
      purpose: "Store schema version and configuration metadata"
      columns:
        - name: "key"
          type: "TEXT"
          constraints: ["PRIMARY KEY", "NOT NULL"]
          description: "Metadata key (e.g., 'schema_version')"

        - name: "value"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Metadata value (stored as text, parse as needed)"

        - name: "updated_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Last update timestamp"

      indexes: []
      foreign_keys: []

      required_keys:
        - key: "schema_version"
          description: "Current schema version (sequential integer as string)"
          example: "1"

        - key: "created_at"
          description: "Database creation timestamp"
          example: "1699900000"

        - key: "last_indexed_at"
          description: "Last full indexing operation timestamp"
          example: "1699900000"

    # -------------------------------------------------------------------------
    # MIGRATION_HISTORY TABLE
    # -------------------------------------------------------------------------
    migration_history:
      purpose: "Track applied schema migrations for idempotent execution"
      columns:
        - name: "id"
          type: "INTEGER"
          constraints: ["PRIMARY KEY", "AUTOINCREMENT"]
          description: "Auto-incrementing unique identifier"

        - name: "version"
          type: "TEXT"
          constraints: ["NOT NULL", "UNIQUE"]
          description: "Migration version (e.g., '001', '002', '003')"

        - name: "description"
          type: "TEXT"
          constraints: ["NOT NULL"]
          description: "Human-readable migration description"

        - name: "applied_at"
          type: "INTEGER"
          constraints: ["NOT NULL"]
          default: "unixepoch()"
          description: "Application timestamp"

      indexes:
        - name: "idx_migration_version"
          type: "UNIQUE"
          columns: ["version"]
          purpose: "Ensure each migration is applied once"

      foreign_keys: []

# =============================================================================
# QUERY CONTRACTS - Interface Level
# =============================================================================

query_contracts:

  # ---------------------------------------------------------------------------
  # Symbol Lookup Operations
  # ---------------------------------------------------------------------------
  symbol_lookup_by_name:
    description: "Find symbols by name across all files"
    target_performance: "<50ms for medium repos (100k+ symbols)"
    query: |
      SELECT s.*, f.file_path, f.language
      FROM symbols s
      JOIN files f ON s.file_id = f.id
      WHERE s.symbol_name = ?
        AND s.deleted_at IS NULL
        AND f.deleted_at IS NULL
      ORDER BY f.file_path;
    parameters:
      - name: "symbol_name"
        type: "string"
        example: "myFunction"
    returns:
      - symbol_id: "TEXT"
      - symbol_name: "TEXT"
      - symbol_type: "TEXT"
      - signature: "TEXT"
      - documentation: "TEXT"
      - file_path: "TEXT"
      - language: "TEXT"
      - line_start: "INTEGER"
      - line_end: "INTEGER"
    index_used: "idx_symbols_name"

  symbol_lookup_by_file:
    description: "Find all symbols in a specific file"
    target_performance: "<50ms"
    query: |
      SELECT *
      FROM symbols
      WHERE file_id = ?
        AND deleted_at IS NULL
      ORDER BY line_start;
    parameters:
      - name: "file_id"
        type: "string"
        example: "uuid-or-hash"
    index_used: "idx_symbols_file_type (leftmost prefix)"

  symbol_lookup_by_file_and_type:
    description: "Find symbols of specific type in a file"
    target_performance: "<50ms"
    query: |
      SELECT *
      FROM symbols
      WHERE file_id = ?
        AND symbol_type = ?
        AND deleted_at IS NULL
      ORDER BY line_start;
    parameters:
      - name: "file_id"
        type: "string"
      - name: "symbol_type"
        type: "string"
        example: "function"
    index_used: "idx_symbols_file_type (full compound index)"

  # ---------------------------------------------------------------------------
  # Cross-Reference Traversal
  # ---------------------------------------------------------------------------
  find_symbol_usages:
    description: "Find all places where a symbol is referenced (inbound refs)"
    target_performance: "<100ms"
    query: |
      SELECT
        x.*,
        s.symbol_name as source_name,
        s.symbol_type as source_type,
        f.file_path as source_file
      FROM xrefs x
      JOIN symbols s ON x.source_symbol_id = s.id
      JOIN files f ON s.file_id = f.id
      WHERE x.target_symbol_id = ?
        AND s.deleted_at IS NULL
        AND f.deleted_at IS NULL
      ORDER BY f.file_path, x.line_number;
    parameters:
      - name: "target_symbol_id"
        type: "string"
    index_used: "idx_xrefs_target"

  find_symbol_references:
    description: "Find all symbols referenced by a symbol (outbound refs)"
    target_performance: "<100ms"
    query: |
      SELECT
        x.*,
        s.symbol_name as target_name,
        s.symbol_type as target_type,
        f.file_path as target_file
      FROM xrefs x
      JOIN symbols s ON x.target_symbol_id = s.id
      JOIN files f ON s.file_id = f.id
      WHERE x.source_symbol_id = ?
        AND s.deleted_at IS NULL
        AND f.deleted_at IS NULL
      ORDER BY x.reference_type, f.file_path;
    parameters:
      - name: "source_symbol_id"
        type: "string"
    index_used: "idx_xrefs_source"

  # ---------------------------------------------------------------------------
  # Full-Text Search
  # ---------------------------------------------------------------------------
  full_text_search:
    description: "Search code and documentation using full-text query"
    target_performance: "<100ms for 1GB codebase"
    query: |
      SELECT
        file_path,
        symbol_id,
        snippet(search, 0, '<mark>', '</mark>', '...', 32) as snippet,
        bm25(search, 2.0, 1.0) as rank
      FROM search
      WHERE search MATCH ?
      ORDER BY rank
      LIMIT ?;
    parameters:
      - name: "query"
        type: "string"
        example: "error handling"
        notes: "Supports prefix (*), phrase (\"\"), AND, OR, NOT operators"
      - name: "limit"
        type: "integer"
        default: 100
    returns:
      - file_path: "TEXT"
      - symbol_id: "TEXT"
      - snippet: "TEXT (with <mark> highlighting)"
      - rank: "REAL (lower = more relevant)"
    index_used: "FTS5 automatic indexes"

  phrase_search:
    description: "Search for exact phrases in code"
    target_performance: "<100ms"
    query: |
      SELECT
        file_path,
        highlight(search, 0, '<mark>', '</mark>') as content,
        bm25(search) as rank
      FROM search
      WHERE search MATCH ?
      ORDER BY rank
      LIMIT ?;
    parameters:
      - name: "phrase_query"
        type: "string"
        example: '"async function"'
        notes: "Must be quoted for exact phrase matching"
    index_used: "FTS5 automatic indexes"

  # ---------------------------------------------------------------------------
  # Chunk Similarity Search (Application-Level)
  # ---------------------------------------------------------------------------
  chunk_similarity_search:
    description: "Find semantically similar code chunks (application-level operation)"
    target_performance: "<200ms for 100k chunks"
    implementation: "application-level"
    steps:
      - step: 1
        description: "Retrieve all embeddings from database"
        query: "SELECT chunk_id, embedding FROM embeddings;"

      - step: 2
        description: "Decode embeddings to Float32Array in application code"
        language: "TypeScript"

      - step: 3
        description: "Compute cosine similarity for each embedding vs query vector"
        algorithm: "brute-force cosine similarity"

      - step: 4
        description: "Sort by similarity and return top K results"

      - step: 5
        description: "Join with chunks table to get content"
        query: |
          SELECT c.*, f.file_path, s.symbol_name
          FROM chunks c
          JOIN files f ON c.file_id = f.id
          LEFT JOIN symbols s ON c.symbol_id = s.id
          WHERE c.id IN (?, ?, ?, ...)
          AND c.deleted_at IS NULL;

    performance_notes:
      - "Brute-force acceptable for 10k-100k chunks"
      - "Can optimize with worker threads for parallel processing"
      - "Consider caching embeddings in memory for repeated searches"

  # ---------------------------------------------------------------------------
  # File Change Detection
  # ---------------------------------------------------------------------------
  detect_changed_files:
    description: "Identify files that have changed based on content hash"
    target_performance: "<100ms for 10k files"
    query: |
      SELECT id, file_path, content_hash
      FROM files
      WHERE deleted_at IS NULL;
    implementation_note: >
      Application compares returned hashes with current file hashes.
      Changed files are those where hash differs from database.
    index_used: "PRIMARY KEY scan"

  detect_new_files:
    description: "Identify files not yet indexed"
    query: |
      SELECT file_path FROM files WHERE deleted_at IS NULL;
    implementation_note: >
      Application compares returned paths with current directory listing.
      New files are those not in result set.

  # ---------------------------------------------------------------------------
  # Deleted Symbol Cleanup
  # ---------------------------------------------------------------------------
  cleanup_expired_symbols:
    description: "Remove symbols deleted more than 30 days ago"
    target_performance: "<1s per 10k records"
    query: |
      DELETE FROM symbols
      WHERE deleted_at IS NOT NULL
        AND deleted_at < unixepoch() - (30 * 86400);
    parameters:
      - name: "retention_days"
        type: "integer"
        default: 30
        note: "30 days = 30 * 86400 seconds"
    index_used: "idx_symbols_deleted"
    returns:
      changes: "INTEGER (number of deleted rows)"

  list_deleted_symbols:
    description: "List symbols deleted within retention period"
    query: |
      SELECT
        s.*,
        f.file_path,
        (unixepoch() - s.deleted_at) / 86400.0 as days_since_deletion
      FROM symbols s
      JOIN files f ON s.file_id = f.id
      WHERE s.deleted_at IS NOT NULL
        AND s.deleted_at > unixepoch() - (30 * 86400)
      ORDER BY s.deleted_at DESC;
    index_used: "idx_symbols_deleted"

# =============================================================================
# MIGRATION CONTRACTS
# =============================================================================

migration_contracts:

  version_tracking:
    description: "Schema version tracking mechanism"
    version_storage: "meta table, key='schema_version'"
    version_format: "sequential integers as strings (e.g., '1', '2', '3')"
    initial_version: "1"

  migration_files:
    location: "sql/migrations/"
    naming_convention: "{version}_{description}.sql"
    examples:
      - "001_initial_schema.sql"
      - "002_add_embeddings.sql"
      - "003_add_call_tracking.sql"
    ordering: "lexicographic (zero-padded version numbers)"

  migration_application:
    rules:
      - rule: "Sequential execution"
        description: "Migrations must be applied in version order"

      - rule: "Transactional"
        description: "Each migration wrapped in BEGIN/COMMIT transaction"
        error_handling: "ROLLBACK on failure, halt migration process"

      - rule: "Idempotent detection"
        description: "Check migration_history before applying"
        query: "SELECT 1 FROM migration_history WHERE version = ?"

      - rule: "History recording"
        description: "Record successful migration in migration_history"
        query: |
          INSERT INTO migration_history (version, description)
          VALUES (?, ?);

      - rule: "Version update"
        description: "Update schema_version in meta table"
        query: |
          UPDATE meta
          SET value = ?, updated_at = unixepoch()
          WHERE key = 'schema_version';

    migration_workflow:
      - step: 1
        action: "Read current schema version from meta table"
        query: "SELECT value FROM meta WHERE key = 'schema_version';"

      - step: 2
        action: "List pending migrations (version > current)"

      - step: 3
        action: "For each pending migration:"
        substeps:
          - "BEGIN TRANSACTION"
          - "Execute migration SQL"
          - "INSERT into migration_history"
          - "UPDATE meta schema_version"
          - "COMMIT"

      - step: 4
        action: "On failure:"
        substeps:
          - "ROLLBACK"
          - "Log error with structured context"
          - "Halt migration process"

  integrity_checks:
    requirement: "PRAGMA integrity_check must pass after migrations"

    integrity_check_query:
      query: "PRAGMA integrity_check;"
      expected_result: "ok"
      on_failure: "Database corruption detected, restore from backup"

    foreign_key_check:
      query: "PRAGMA foreign_key_check;"
      expected_result: "empty result set"
      on_failure: "Foreign key violations detected"

    index_check:
      description: "Verify all expected indexes exist"
      query: |
        SELECT name, tbl_name, sql
        FROM sqlite_master
        WHERE type = 'index'
        ORDER BY tbl_name, name;
      validation: "Compare against expected index list"

  backup_strategy:
    pre_migration_backup:
      command: "VACUUM INTO 'backup-{timestamp}.db';"
      retention: "Keep last 3 backups"

    rollback_procedure:
      - "Stop application"
      - "Replace index.db with backup file"
      - "Restart application"
      - "Verify integrity"

# =============================================================================
# LOGGING CONTRACTS
# =============================================================================

logging_contracts:

  error_logging:
    description: "Structured logging for all database errors"
    format: "JSON lines (JSONL)"
    location: ".codeindex/logs/db-errors.jsonl"

    required_fields:
      - field: "timestamp"
        type: "string"
        format: "ISO 8601"
        example: "2025-10-13T15:30:45.123Z"

      - field: "level"
        type: "string"
        values: ["error", "fatal"]

      - field: "operation"
        type: "string"
        description: "Database operation type"
        examples: ["query", "insert", "update", "delete", "transaction", "migration"]

      - field: "query"
        type: "string"
        description: "SQL query that failed (parameterized, no values)"

      - field: "parameters"
        type: "array"
        description: "Query parameters (redacted if sensitive)"

      - field: "error_code"
        type: "string"
        description: "SQLite error code"
        examples: ["SQLITE_BUSY", "SQLITE_CONSTRAINT", "SQLITE_CORRUPT"]

      - field: "error_message"
        type: "string"
        description: "Human-readable error message"

      - field: "stack_trace"
        type: "string"
        description: "JavaScript stack trace"

      - field: "context"
        type: "object"
        description: "Additional context (user action, file path, etc.)"

    example_log_entry:
      timestamp: "2025-10-13T15:30:45.123Z"
      level: "error"
      operation: "insert"
      query: "INSERT INTO symbols (id, file_id, symbol_name, ...) VALUES (?, ?, ?, ...)"
      parameters: ["uuid-123", "file-456", "myFunction"]
      error_code: "SQLITE_CONSTRAINT"
      error_message: "UNIQUE constraint failed: symbols.id"
      stack_trace: "Error: ...\n    at Database.insert (/path/to/file.ts:123:45)"
      context:
        command: "index"
        file_path: "src/index.ts"

  slow_query_logging:
    description: "Log queries exceeding performance thresholds"
    format: "JSON lines (JSONL)"
    location: ".codeindex/logs/slow-queries.jsonl"

    thresholds:
      - operation: "symbol_query"
        threshold_ms: 50

      - operation: "search_query"
        threshold_ms: 100

      - operation: "xref_query"
        threshold_ms: 100

      - operation: "write_operation"
        threshold_ms: 1000

    required_fields:
      - field: "timestamp"
        type: "string"
        format: "ISO 8601"

      - field: "level"
        type: "string"
        value: "warn"

      - field: "operation"
        type: "string"
        description: "Query operation type"

      - field: "query"
        type: "string"
        description: "SQL query (parameterized)"

      - field: "parameters"
        type: "array"
        description: "Query parameters"

      - field: "duration_ms"
        type: "number"
        description: "Query execution time in milliseconds"

      - field: "result_count"
        type: "integer"
        description: "Number of rows returned"

      - field: "threshold_ms"
        type: "number"
        description: "Expected threshold for this operation"

      - field: "explain_plan"
        type: "string"
        description: "EXPLAIN QUERY PLAN output for analysis"
        note: "Optional, can be expensive to collect"

    example_log_entry:
      timestamp: "2025-10-13T15:30:45.123Z"
      level: "warn"
      operation: "symbol_query"
      query: "SELECT * FROM symbols WHERE symbol_name = ? AND deleted_at IS NULL"
      parameters: ["myFunction"]
      duration_ms: 87
      result_count: 234
      threshold_ms: 50
      explain_plan: "SEARCH TABLE symbols USING INDEX idx_symbols_name (symbol_name=?)"

  performance_monitoring:
    description: "Periodic performance metrics logging"
    format: "JSON lines (JSONL)"
    location: ".codeindex/logs/performance.jsonl"
    frequency: "On command completion"

    metrics:
      - metric: "database_size_mb"
        description: "Total database file size"

      - metric: "wal_size_mb"
        description: "WAL file size"

      - metric: "table_row_counts"
        description: "Row count per table"

      - metric: "index_size_mb"
        description: "Total index size"

      - metric: "query_count"
        description: "Total queries executed in session"

      - metric: "average_query_time_ms"
        description: "Average query execution time"

    example_log_entry:
      timestamp: "2025-10-13T15:30:45.123Z"
      level: "info"
      command: "index"
      duration_ms: 12345
      files_processed: 1234
      symbols_indexed: 5678
      database_size_mb: 45.2
      wal_size_mb: 2.1
      table_row_counts:
        files: 1234
        symbols: 5678
        xrefs: 12345
        chunks: 5000
        embeddings: 5000
      index_size_mb: 12.3
      query_count: 45678
      average_query_time_ms: 3.2

# =============================================================================
# VALIDATION RULES
# =============================================================================

validation:

  on_startup:
    - check: "Database file exists and is readable"
      error: "Database not initialized, run 'code-index init'"

    - check: "PRAGMA integrity_check = 'ok'"
      error: "Database corruption detected, restore from backup"

    - check: "PRAGMA foreign_key_check returns empty"
      error: "Foreign key violations detected"

    - check: "Required tables exist"
      query: |
        SELECT name FROM sqlite_master
        WHERE type = 'table'
        AND name IN ('files', 'symbols', 'xrefs', 'calls', 'chunks', 'embeddings', 'meta', 'migration_history');
      expected: "8 tables"

    - check: "Required indexes exist"
      query: |
        SELECT name FROM sqlite_master
        WHERE type = 'index'
        AND name LIKE 'idx_%';
      validation: "Compare against expected index list"

    - check: "Schema version is current"
      query: "SELECT value FROM meta WHERE key = 'schema_version';"
      action: "Run migrations if behind"

  on_write:
    - check: "Single-writer enforcement"
      method: "BEGIN IMMEDIATE transaction"
      error: "SQLITE_BUSY: Another write operation in progress"

    - check: "Disk space available"
      method: "Check available disk space before large writes"
      threshold: "500MB free minimum"

  periodic:
    - check: "WAL checkpoint"
      frequency: "Every 1000 pages"
      command: "PRAGMA wal_checkpoint(PASSIVE);"

    - check: "Analyze statistics"
      frequency: "After bulk operations"
      command: "ANALYZE;"

    - check: "Cleanup deleted symbols"
      frequency: "Daily"
      query: "DELETE FROM symbols WHERE deleted_at < unixepoch() - (30 * 86400);"

    - check: "VACUUM (optional)"
      frequency: "After large cleanup operations"
      command: "VACUUM;"
      note: "Expensive operation, run when idle"

# =============================================================================
# PERFORMANCE BENCHMARKS
# =============================================================================

performance_benchmarks:

  test_conditions:
    repository_size: "Medium (10k-100k files, 100k+ symbols)"
    hardware: "Modern laptop (16GB RAM, SSD)"
    database_size: "100MB-1GB"

  targets:
    - operation: "file_by_path"
      target: "<10ms"
      query_type: "indexed_lookup"

    - operation: "symbol_by_name"
      target: "<50ms"
      query_type: "indexed_lookup"
      dataset: "100k+ symbols"

    - operation: "symbol_by_file"
      target: "<50ms"
      query_type: "indexed_lookup"

    - operation: "find_usages"
      target: "<100ms"
      query_type: "join_with_index"

    - operation: "full_text_search"
      target: "<100ms"
      query_type: "fts5_search"
      dataset: "1GB codebase"

    - operation: "similarity_search"
      target: "<200ms"
      query_type: "application_level"
      dataset: "100k embeddings"

    - operation: "batch_insert"
      target: "1000 files in <10s"
      query_type: "transactional_write"

    - operation: "cleanup_deleted"
      target: "<1s per 10k records"
      query_type: "indexed_delete"

  monitoring:
    - metric: "Query execution time"
      log: "slow-queries.jsonl"
      alert_threshold: "2x target performance"

    - metric: "Database size growth"
      log: "performance.jsonl"
      alert_threshold: ">2x source code size"

    - metric: "Index overhead"
      log: "performance.jsonl"
      alert_threshold: ">30% of database size"

# =============================================================================
# CONTRACT VERSION HISTORY
# =============================================================================

contract_history:
  - version: "1.0.0"
    date: "2025-10-13"
    changes: "Initial schema contract based on spec and research"
    author: "Claude Code Agent"
